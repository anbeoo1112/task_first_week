"""Test suy luáº­n vá»›i extract_thinker + Ollama"""
import os
from dotenv import load_dotenv

load_dotenv()

def test_ollama_direct():
    """Test Ollama trá»±c tiáº¿p"""
    print("=" * 60)
    print("ğŸ§  TEST OLLAMA TRá»°C TIáº¾P")
    print("=" * 60)
    
    import requests
    
    prompt = "Xin chÃ o, báº¡n lÃ  ai?"
    
    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "qwen2.5:3b",
                "prompt": prompt,
                "stream": False
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Ollama hoáº¡t Ä‘á»™ng!")
            print(f"ğŸ“ Response: {result.get('response', 'N/A')[:500]}")
            return True
        else:
            print(f"âŒ Lá»—i: {response.status_code}")
            print(response.text)
            return False
            
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i Ollama: {e}")
        return False


def test_litellm():
    """Test LiteLLM vá»›i Ollama"""
    print("\n" + "=" * 60)
    print("ğŸ§  TEST LITELLM + OLLAMA")
    print("=" * 60)
    
    try:
        from litellm import completion
        
        response = completion(
            model="ollama/qwen2.5:3b",
            messages=[{"role": "user", "content": "Xin chÃ o, báº¡n lÃ  ai?"}],
            api_base="http://localhost:11434"
        )
        
        print(f"âœ… LiteLLM hoáº¡t Ä‘á»™ng!")
        print(f"ğŸ“ Response: {response.choices[0].message.content[:500]}")
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i LiteLLM: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_extract_thinker_classify(file_path: str):
    """Test phÃ¢n loáº¡i vá»›i extract_thinker"""
    print("\n" + "=" * 60)
    print("ğŸ” TEST EXTRACT_THINKER CLASSIFY")
    print("=" * 60)
    
    try:
        from extract_thinker import (
            Extractor,
            Classification,
            DocumentLoaderGoogleDocumentAI,
            GoogleDocAIConfig,
        )
        
        # Setup
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("DOCUMENTAI_GOOGLE_CREDENTIALS", "credentials.json")
        
        config = GoogleDocAIConfig(
            project_id=os.getenv("DOCUMENTAI_PROJECT_ID"),
            location=os.getenv("DOCUMENTAI_LOCATION", "us"),
            processor_id=os.getenv("DOCUMENTAI_PROCESSOR_ID"),
            credentials=os.getenv("DOCUMENTAI_GOOGLE_CREDENTIALS", "credentials.json")
        )
        
        extractor = Extractor()
        extractor.load_document_loader(DocumentLoaderGoogleDocumentAI(config))
        extractor.load_llm("ollama/qwen2.5:3b")
        
        print(f"ğŸ“ File: {file_path}")
        print(f"ğŸ¤– Model: ollama/qwen2.5:3b")
        
        # Classifications Ä‘Æ¡n giáº£n
        classifications = [
            Classification(name="identity", description="Giáº¥y tá» tÃ¹y thÃ¢n: CCCD, há»™ chiáº¿u, giáº¥y khai sinh"),
            Classification(name="vehicle", description="Giáº¥y tá» phÆ°Æ¡ng tiá»‡n: báº±ng lÃ¡i, Ä‘Äƒng kÃ½ xe"),
            Classification(name="finance", description="Giáº¥y tá» tÃ i chÃ­nh: hÃ³a Ä‘Æ¡n, biÃªn lai, há»£p Ä‘á»“ng"),
        ]
        
        print("\nâ³ Äang phÃ¢n loáº¡i...")
        result = extractor.classify(file_path, classifications)
        
        print(f"\nâœ… PhÃ¢n loáº¡i thÃ nh cÃ´ng!")
        print(f"ğŸ“Œ Káº¿t quáº£: {result}")
        print(f"ğŸ“Œ Name: {getattr(result, 'name', 'N/A')}")
        print(f"ğŸ“Œ Confidence: {getattr(result, 'confidence', 'N/A')}")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ Lá»—i: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_extract_thinker_extract(file_path: str):
    """Test trÃ­ch xuáº¥t vá»›i extract_thinker"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ TEST EXTRACT_THINKER EXTRACT")
    print("=" * 60)
    
    try:
        from extract_thinker import (
            Extractor,
            DocumentLoaderGoogleDocumentAI,
            GoogleDocAIConfig,
        )
        from pydantic import BaseModel, Field
        from typing import Optional
        
        # Contract Ä‘Æ¡n giáº£n
        class SimpleContract(BaseModel):
            """ThÃ´ng tin cÆ¡ báº£n tá»« vÄƒn báº£n"""
            ten: Optional[str] = Field(None, description="Há» vÃ  tÃªn")
            so_giay_to: Optional[str] = Field(None, description="Sá»‘ CCCD/CMND/Há»™ chiáº¿u")
            ngay_sinh: Optional[str] = Field(None, description="NgÃ y thÃ¡ng nÄƒm sinh")
        
        # Setup
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("DOCUMENTAI_GOOGLE_CREDENTIALS", "credentials.json")
        
        config = GoogleDocAIConfig(
            project_id=os.getenv("DOCUMENTAI_PROJECT_ID"),
            location=os.getenv("DOCUMENTAI_LOCATION", "us"),
            processor_id=os.getenv("DOCUMENTAI_PROCESSOR_ID"),
            credentials=os.getenv("DOCUMENTAI_GOOGLE_CREDENTIALS", "credentials.json")
        )
        
        extractor = Extractor()
        extractor.load_document_loader(DocumentLoaderGoogleDocumentAI(config))
        extractor.load_llm("ollama/qwen2.5:3b")
        
        print(f"ğŸ“ File: {file_path}")
        print(f"ğŸ¤– Model: ollama/qwen2.5:3b")
        
        print("\nâ³ Äang trÃ­ch xuáº¥t...")
        result = extractor.extract(file_path, SimpleContract)
        
        print(f"\nâœ… TrÃ­ch xuáº¥t thÃ nh cÃ´ng!")
        print(f"ğŸ“Œ Káº¿t quáº£: {result}")
        if result:
            print(f"ğŸ“Œ Data: {result.model_dump()}")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ Lá»—i: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    import sys
    
    print("ğŸš€ KIá»‚M TRA SUY LUáº¬N (INFERENCE)")
    print("=" * 60)
    
    # Test 1: Ollama trá»±c tiáº¿p
    if not test_ollama_direct():
        print("\nâš ï¸ Ollama khÃ´ng hoáº¡t Ä‘á»™ng!")
        sys.exit(1)
    
    # Test 2: LiteLLM
    test_litellm()
    
    # Test 3 & 4: Extract Thinker (náº¿u cÃ³ file)
    if len(sys.argv) >= 2:
        file_path = sys.argv[1]
        if os.path.exists(file_path):
            test_extract_thinker_classify(file_path)
            test_extract_thinker_extract(file_path)
        else:
            print(f"\nâŒ File khÃ´ng tá»“n táº¡i: {file_path}")
    else:
        print("\nğŸ’¡ Äá»ƒ test vá»›i file, cháº¡y: python test_inference.py <file_path>")
